"""
æ™ºèƒ½æ‘˜è¦ç³»ç»Ÿ
ç”Ÿæˆç« èŠ‚æ‘˜è¦ï¼Œä¿ç•™å…³é”®ä¿¡æ¯
"""

import json
from typing import Dict, List, Any
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

class SmartSummarizer:
    """æ™ºèƒ½æ‘˜è¦ç³»ç»Ÿ"""
    
    def __init__(self, llm=None):
        self.llm = llm
        self._init_templates()
    
    def _init_templates(self):
        """åˆå§‹åŒ–æ‘˜è¦æ¨¡æ¿"""
        
        # ç« èŠ‚æ‘˜è¦æ¨¡æ¿
        self.chapter_summary_template = PromptTemplate(
            input_variables=["content", "chapter_number"],
            template="""
            è¯·ä¸ºä»¥ä¸‹å°è¯´ç« èŠ‚ç”Ÿæˆæ™ºèƒ½æ‘˜è¦ï¼š
            
            ç« èŠ‚ç¼–å·ï¼š{chapter_number}
            ç« èŠ‚å†…å®¹ï¼š
            {content}
            
            è¦æ±‚ï¼š
            1. æå–é‡è¦æƒ…èŠ‚è¿›å±•ï¼ˆ50-100å­—ï¼‰
            2. è®°å½•äººç‰©å…³ç³»å˜åŒ–
            3. æ ‡è®°æ–°å‡ºç°çš„è®¾å®šæˆ–ä¼ç¬”
            4. æ€»ç»“å…³é”®å¯¹è¯å’Œå†³ç­–
            5. æ§åˆ¶åœ¨200å­—ä»¥å†…
            
            è¾“å‡ºæ ¼å¼ï¼š
            {{
                "summary": "æ‘˜è¦å†…å®¹",
                "key_events": ["äº‹ä»¶1", "äº‹ä»¶2", "äº‹ä»¶3"],
                "character_development": {{
                    "äººç‰©1": "å‘å±•æè¿°",
                    "äººç‰©2": "å‘å±•æè¿°"
                }},
                "new_elements": ["æ–°è®¾å®š1", "æ–°ä¼ç¬”1"],
                "word_count": æ‘˜è¦å­—æ•°
            }}
            """
        )
        
        # å·æ‘˜è¦æ¨¡æ¿
        self.volume_summary_template = PromptTemplate(
            input_variables=["chapter_summaries", "volume_number"],
            template="""
            åŸºäºä»¥ä¸‹ç« èŠ‚æ‘˜è¦ï¼Œç”Ÿæˆæœ¬å·çš„æ€»ä½“æ‘˜è¦ï¼š
            
            å·å·ï¼š{volume_number}
            ç« èŠ‚æ‘˜è¦ï¼š
            {chapter_summaries}
            
            è¦æ±‚ï¼š
            1. æ€»ç»“æœ¬å·çš„ä¸»è¦æƒ…èŠ‚å‘å±•
            2. æ¢³ç†äººç‰©æˆé•¿å’Œå…³ç³»å˜åŒ–
            3. å½’çº³æœ¬å·çš„æ ¸å¿ƒå†²çª
            4. åˆ†ææƒ…èŠ‚æ¨è¿›çš„å…³é”®èŠ‚ç‚¹
            5. æ§åˆ¶åœ¨300å­—ä»¥å†…
            
            è¾“å‡ºæ ¼å¼ï¼š
            {{
                "summary": "å·æ‘˜è¦",
                "main_plot": "ä¸»è¦æƒ…èŠ‚",
                "character_arcs": "äººç‰©å¼§å…‰",
                "key_turning_points": ["è½¬æŠ˜ç‚¹1", "è½¬æŠ˜ç‚¹2"],
                "setup_for_next": "ä¸ºä¸‹ä¸€å·çš„é“ºå«"
            }}
            """
        )
    
    def create_chapter_summary(self, content: str, chapter_number: int) -> Dict[str, Any]:
        """
        ç”Ÿæˆç« èŠ‚æ‘˜è¦
        
        Args:
            content: ç« èŠ‚å†…å®¹
            chapter_number: ç« èŠ‚ç¼–å·
            
        Returns:
            æ‘˜è¦å­—å…¸
        """
        if self.llm:
            # ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½æ‘˜è¦
            chain = LLMChain(
                llm=self.llm,
                prompt=self.chapter_summary_template
            )
            
            result = chain.run(
                content=content[:5000],  # é™åˆ¶é•¿åº¦
                chapter_number=chapter_number
            )
            
            try:
                return json.loads(result)
            except:
                return {
                    "summary": result[:200] + "..." if len(result) > 200 else result,
                    "key_events": [],
                    "character_development": {},
                    "new_elements": [],
                    "word_count": len(result)
                }
        else:
            # ç®€å•å®ç°ï¼šæå–å‰200å­—ä½œä¸ºæ‘˜è¦
            return {
                "summary": content[:200] + "..." if len(content) > 200 else content,
                "key_events": [],
                "character_development": {},
                "new_elements": [],
                "word_count": min(200, len(content))
            }
    
    def create_volume_summary(self, chapter_summaries: List[Dict[str, Any]], 
                             volume_number: int) -> Dict[str, Any]:
        """
        ç”Ÿæˆå·æ‘˜è¦
        
        Args:
            chapter_summaries: ç« èŠ‚æ‘˜è¦åˆ—è¡¨
            volume_number: å·å·
            
        Returns:
            å·æ‘˜è¦å­—å…¸
        """
        if self.llm and chapter_summaries:
            # å‡†å¤‡ç« èŠ‚æ‘˜è¦æ–‡æœ¬
            summaries_text = ""
            for i, summary in enumerate(chapter_summaries, 1):
                summaries_text += f"ç¬¬{i}ç« : {summary.get('summary', '')}\n"
            
            chain = LLMChain(
                llm=self.llm,
                prompt=self.volume_summary_template
            )
            
            result = chain.run(
                chapter_summaries=summaries_text,
                volume_number=volume_number
            )
            
            try:
                return json.loads(result)
            except:
                return {
                    "summary": result,
                    "main_plot": "",
                    "character_arcs": "",
                    "key_turning_points": [],
                    "setup_for_next": ""
                }
        else:
            # ç®€å•å®ç°ï¼šåˆå¹¶ç« èŠ‚æ‘˜è¦
            combined_summary = ""
            for summary in chapter_summaries:
                combined_summary += summary.get('summary', '') + " "
            
            return {
                "summary": combined_summary[:300] + "..." if len(combined_summary) > 300 else combined_summary,
                "main_plot": "",
                "character_arcs": "",
                "key_turning_points": [],
                "setup_for_next": ""
            }
    
    def extract_key_information(self, content: str) -> Dict[str, Any]:
        """
        ä»å†…å®¹ä¸­æå–å…³é”®ä¿¡æ¯
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            
        Returns:
            å…³é”®ä¿¡æ¯å­—å…¸
        """
        # ç®€å•å®ç°ï¼šæå–é‡è¦å…ƒç´ 
        import re
        
        info = {
            "mentioned_characters": [],
            "important_events": [],
            "new_settings": [],
            "potential_foreshadowing": []
        }
        
        # æå–å¯èƒ½çš„äººç‰©åç§°ï¼ˆä¸­æ–‡åç§°ï¼Œ2-4å­—ï¼‰
        chinese_names = re.findall(r'[\u4e00-\u9fa5]{2,4}[\u4e00-\u9fa5]', content)
        info["mentioned_characters"] = list(set(chinese_names))[:10]  # å»é‡ï¼Œæœ€å¤š10ä¸ª
        
        # æå–é‡è¦äº‹ä»¶ï¼ˆåŒ…å«åŠ¨è¯çš„çŸ­å¥ï¼‰
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
        important_sentences = []
        
        important_indicators = ['å‘ç°', 'é‡åˆ°', 'æˆ˜æ–—', 'æ­»äº¡', 'è·å¾—', 'å¤±å»', 'å†³å®š', 'æ‰¿è¯º']
        for sentence in sentences:
            if any(indicator in sentence for indicator in important_indicators):
                important_sentences.append(sentence.strip())
        
        info["important_events"] = important_sentences[:5]
        
        # æå–å¯èƒ½çš„æ–°è®¾å®š
        setting_indicators = ['ä¸–ç•Œ', 'æ³•åˆ™', 'åŠ›é‡', 'ç³»ç»Ÿ', 'ç»„ç»‡', 'é—¨æ´¾']
        for sentence in sentences:
            if any(indicator in sentence for indicator in setting_indicators):
                info["new_settings"].append(sentence.strip())
        
        info["new_settings"] = info["new_settings"][:3]
        
        # æå–å¯èƒ½çš„ä¼ç¬”
        foreshadowing_indicators = ['æœªæ¥', 'å°†ä¼š', 'å¯èƒ½', 'ä¼¼ä¹', 'æš—ç¤º', 'é¢„å…†']
        for sentence in sentences:
            if any(indicator in sentence for indicator in foreshadowing_indicators):
                info["potential_foreshadowing"].append(sentence.strip())
        
        info["potential_foreshadowing"] = info["potential_foreshadowing"][:3]
        
        return info
    
    def create_reading_notes(self, chapter_summaries: List[Dict[str, Any]]) -> str:
        """
        ç”Ÿæˆé˜…è¯»ç¬”è®°
        
        Args:
            chapter_summaries: ç« èŠ‚æ‘˜è¦åˆ—è¡¨
            
        Returns:
            é˜…è¯»ç¬”è®°
        """
        if not chapter_summaries:
            return "æš‚æ— é˜…è¯»ç¬”è®°"
        
        notes = "ğŸ“š é˜…è¯»ç¬”è®°\n\n"
        
        # æŒ‰ç« èŠ‚ç»„ç»‡ç¬”è®°
        for i, summary in enumerate(chapter_summaries, 1):
            notes += f"## ç¬¬{i}ç« \n"
            notes += f"{summary.get('summary', '')}\n\n"
            
            key_events = summary.get('key_events', [])
            if key_events:
                notes += "å…³é”®äº‹ä»¶:\n"
                for event in key_events:
                    notes += f"- {event}\n"
                notes += "\n"
            
            character_dev = summary.get('character_development', {})
            if character_dev:
                notes += "äººç‰©å‘å±•:\n"
                for char, dev in character_dev.items():
                    notes += f"- {char}: {dev}\n"
                notes += "\n"
        
        return notes
    
    def calculate_complexity_score(self, content: str) -> float:
        """
        è®¡ç®—å†…å®¹å¤æ‚åº¦
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            
        Returns:
            å¤æ‚åº¦åˆ†æ•° (0-1)
        """
        if not content:
            return 0.0
        
        # ç®€å•å¤æ‚åº¦è®¡ç®—
        import re
        
        # å¥å­æ•°é‡
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
        sentence_count = len([s for s in sentences if s.strip()])
        
        # æ®µè½æ•°é‡
        paragraphs = content.split('\n')
        paragraph_count = len([p for p in paragraphs if p.strip()])
        
        # è¯æ±‡å¤šæ ·æ€§
        words = re.findall(r'[\u4e00-\u9fa5]+', content)
        unique_words = set(words)
        
        if words:
            diversity = len(unique_words) / len(words)
        else:
            diversity = 0
        
        # è®¡ç®—ç»¼åˆåˆ†æ•°
        complexity = min(1.0, (
            (sentence_count / 100) * 0.3 +
            (paragraph_count / 10) * 0.2 +
            diversity * 0.5
        ))
        
        return complexity

# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    summarizer = SmartSummarizer()
    
    # æµ‹è¯•æ•°æ®
    test_content = """
    ç¬¬ä¸€ç« ï¼šç©¿è¶Š
    
    æå‡¡çå¼€çœ¼ç›ï¼Œå‘ç°è‡ªå·±èººåœ¨ä¸€ä¸ªé™Œç”Ÿçš„æˆ¿é—´é‡Œã€‚
    æˆ¿é—´çš„è£…é¥°å¤è‰²å¤é¦™ï¼Œçª—å¤–çš„æ™¯è‰²æ›´æ˜¯è®©ä»–éœ‡æƒŠâ€”â€”ä»™é¹¤åœ¨ç©ºä¸­é£ç¿”ï¼Œè¿œå¤„æœ‰ä¿®å£«å¾¡å‰‘é£è¡Œã€‚
    
    "æˆ‘è¿™æ˜¯ç©¿è¶Šäº†ï¼Ÿ"æå‡¡å–ƒå–ƒè‡ªè¯­ã€‚
    
    è¿™æ—¶ï¼Œé—¨å¤–ä¼ æ¥è„šæ­¥å£°ã€‚ä¸€ä¸ªç©¿ç€é“è¢çš„è€è€…æ¨é—¨è€Œå…¥ã€‚
    "ä½ é†’äº†ï¼Ÿ"è€è€…é—®é“ï¼Œ"æˆ‘æ˜¯é’äº‘å®—çš„æŒé—¨ï¼Œä½ åœ¨åå±±æ˜è¿·äº†ä¸‰å¤©ã€‚"
    
    æå‡¡æ„è¯†åˆ°ï¼Œä»–ä¸ä»…ç©¿è¶Šäº†ï¼Œè¿˜ç©¿è¶Šåˆ°äº†ä¸€ä¸ªä¿®çœŸä¸–ç•Œã€‚
    """
    
    # æµ‹è¯•ç« èŠ‚æ‘˜è¦
    chapter_summary = summarizer.create_chapter_summary(test_content, 1)
    print("ç« èŠ‚æ‘˜è¦:")
    print(json.dumps(chapter_summary, indent=2, ensure_ascii=False))
    
    # æµ‹è¯•å…³é”®ä¿¡æ¯æå–
    key_info = summarizer.extract_key_information(test_content)
    print("\nå…³é”®ä¿¡æ¯:")
    print(json.dumps(key_info, indent=2, ensure_ascii=False))
    
    # æµ‹è¯•å¤æ‚åº¦è®¡ç®—
    complexity = summarizer.calculate_complexity_score(test_content)
    print(f"\nå†…å®¹å¤æ‚åº¦: {complexity:.2f}")
    
    # æµ‹è¯•é˜…è¯»ç¬”è®°
    reading_notes = summarizer.create_reading_notes([chapter_summary])
    print("\né˜…è¯»ç¬”è®°:")
    print(reading_notes[:500])